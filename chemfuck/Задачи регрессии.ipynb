{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequality_clear.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop('color', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], shuffle=True,\n",
    "                                                     stratify=df.iloc[:,-1], train_size=0.8, random_state=1240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5170, 11) (1293, 11) (1293,) (5170,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1354    7.0\n",
       "5569    6.0\n",
       "3315    6.0\n",
       "5016    5.0\n",
       "1304    6.0\n",
       "       ... \n",
       "1079    5.0\n",
       "6330    6.0\n",
       "473     6.0\n",
       "3705    6.0\n",
       "2618    5.0\n",
       "Name: quality, Length: 1293, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.astype(float)\n",
    "y_test.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценки качества регрессии:\n",
    "\n",
    "Средняя абсолютная ошибка MAE (абсолютная разница между рассчётным и нужным усредняем) metrics.mean_absolute_error\n",
    "\n",
    ">>>Средняя квадратичная ошибка MSE (лучше для больших ошибок) metrics.mean_squared_error\n",
    "\n",
    "Корень из среднеквадратичной ошибки RMSE \n",
    "\n",
    "Коэффициент детерминации R2 metrics.r2_score\n",
    "\n",
    "\n",
    "\n",
    "Линейная регрессия (может быть с несколькими xi в первой степени) LinearRegression (fit_intercept - свободный член(True-False), positive(True-False) - положительные значения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr = LinearRegression()\n",
    "rgr.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.28920669e-02 -1.37185711e+00 -1.36758756e-01  4.16652313e-02\n",
      " -7.33671005e-01  6.17230947e-03 -2.68989357e-03 -4.76625676e+01\n",
      "  3.59442054e-01  7.39330340e-01  2.66736219e-01] 48.87217799231189\n"
     ]
    }
   ],
   "source": [
    "print(rgr.coef_,rgr.intercept_) #выводим коэффициенты регрессии и свободный член"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.5220310913426291 \n",
      "R2:  0.3146826262339275\n"
     ]
    }
   ],
   "source": [
    "y_pred = rgr.predict(x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y_pred), '\\nR2: ', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полиномная регрессия \n",
    "\n",
    "Добавляем просто степени на наши формулы\n",
    "\n",
    "Функцию таже LinearRegression, но нужно настроить входные данные как полиномные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5170, 78)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol2 = PolynomialFeatures(degree=2) #делаем вторые степени, добавляет их в выборку\n",
    "p2_x_train = pol2.fit_transform(x_train) #добавляем вторые степени и перекрестные члены\n",
    "p2_x_test = pol2.fit_transform(x_test)\n",
    "p2_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.49705363579741785 \n",
      "R2:  0.34747278858532693\n"
     ]
    }
   ],
   "source": [
    "rgr2 = LinearRegression() #Полимная регрессия с квадратами\n",
    "rgr2.fit(p2_x_train, y_train)\n",
    "y2_pred = rgr2.predict(p2_x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y2_pred), '\\nR2: ', metrics.r2_score(y_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.6180770163397694 \n",
      "R2:  0.18859446372490207\n"
     ]
    }
   ],
   "source": [
    "pol3 = PolynomialFeatures(degree=3) #делаем третьи степени, добавляет их в выборку\n",
    "p3_x_train = pol3.fit_transform(x_train) #добавляем вторые степени и перекрестные члены\n",
    "p3_x_test = pol3.fit_transform(x_test)\n",
    "rgr3 = LinearRegression() #Полимная регрессия с кубами\n",
    "rgr3.fit(p3_x_train, y_train)\n",
    "y3_pred = rgr3.predict(p3_x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y3_pred), '\\nR2: ', metrics.r2_score(y_test, y3_pred)) #Стало ещё хуже чем при второй степени"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно делать регулиризацию - обычно штраф за сложность модели\n",
    "\n",
    "# Гребневая регрессия - ридж-регрессия (делает модель более устойчивой)\n",
    "\n",
    "Тут используется штраф l2 норм это как MSE с членом + g*b^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.524556326802552 \n",
      "R2:  0.31136752151653546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rgr4 = Ridge() #Регрессия гребневая\n",
    "rgr4.fit(x_train, y_train)\n",
    "y4_pred = rgr4.predict(x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y4_pred), '\\nR2: ', metrics.r2_score(y_test, y4_pred)) #Стало ещё хуже чем при второй степени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.28920669e-02 -1.37185711e+00 -1.36758756e-01  4.16652313e-02\n",
      " -7.33671005e-01  6.17230947e-03 -2.68989357e-03 -4.76625676e+01\n",
      "  3.59442054e-01  7.39330340e-01  2.66736219e-01] 48.87217799231189\n",
      "[ 0.01392964 -1.47525592 -0.1422238   0.02376406 -0.80444622  0.00617446\n",
      " -0.00246063 -0.14736289  0.12270475  0.61419072  0.32370704] 2.3045997742398403\n"
     ]
    }
   ],
   "source": [
    "print(rgr.coef_,rgr.intercept_) #коэффициенты обычной регрессии\n",
    "print(rgr4.coef_,rgr4.intercept_) #коэффициенты ридж горозда меньше изменяются, поспокойней - устойчивей"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель LASSO - зануляем совсем незначимые коэффициенты чтобы стабилизироваться Lasso\n",
    "\n",
    "Можно использовать как выбор значимых переменных (shrinkage)\n",
    "\n",
    "Совмещение ридж и лассо = Elastic Net\n",
    "\n",
    "Их общие параметры\n",
    "\n",
    "solver - алгоритм\n",
    "\n",
    "alpha - величина штрафа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.5260074862153077 \n",
      "R2:  0.30946245345802603\n",
      "[ 0.         -1.32703247 -0.          0.02269952 -0.          0.00632455\n",
      " -0.00248516 -0.          0.01220961  0.43850581  0.32810718] 2.5244237455658216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "rgr5= Lasso(alpha=0.0025) #Регрессия лассо\n",
    "rgr5.fit(x_train, y_train)\n",
    "y5_pred = rgr5.predict(x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y5_pred), '\\nR2: ', metrics.r2_score(y_test, y5_pred)) #Убили 4 коэффициента, которые незначимы\n",
    "print(rgr5.coef_,rgr5.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дерево решений для регрессии\n",
    "\n",
    "Минимизируем дисперсию в группах на которые делим\n",
    "\n",
    "Листья заканчиваются вещественным чилом, так что нужно аккуратно обрезать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.5471189144846919 \n",
      "R2:  0.2817475743675596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rgr6= DecisionTreeRegressor(max_depth=7, random_state=1240) #Регрессия деревом\n",
    "rgr6.fit(x_train, y_train)\n",
    "y6_pred = rgr6.predict(x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y6_pred), '\\nR2: ', metrics.r2_score(y_test, y6_pred)) #Так себе\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес\n",
    "\n",
    "Всё как обычно, не то чтобы стабильнл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0.44928672680797976 \n",
      "R2:  0.4101807252665909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rgr7= RandomForestRegressor(max_depth=7, n_estimators=1000) #Регрессия лесом\n",
    "rgr7.fit(x_train, y_train)\n",
    "y7_pred = rgr7.predict(x_test)\n",
    "print('MSE', metrics.mean_squared_error(y_test, y7_pred), '\\nR2: ', metrics.r2_score(y_test, y7_pred)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод k-ближайших соседей\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ненормированные данные\n",
      "MSE 0.6644411825054848 \n",
      "R2:  0.12772803427178114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "rgr8 = KNeighborsRegressor(n_neighbors=7)\n",
    "rgr8.fit(x_train, y_train)\n",
    "y8_pred = rgr8.predict(x_test)\n",
    "print('ненормированные данные\\nMSE', metrics.mean_squared_error(y_test, y8_pred), '\\nR2: ', metrics.r2_score(y_test, y8_pred)) #Ненормированный результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нормированные данные\n",
      "MSE 0.46907208358981634 \n",
      "R2:  0.38420670001480084\n"
     ]
    }
   ],
   "source": [
    "rgr8 = KNeighborsRegressor(n_neighbors=7)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train) #делаем такую функцию для нормирования по x_train\n",
    "x_train_S = scaler.transform(x_train)\n",
    "x_test_S = scaler.transform(x_test)\n",
    "rgr8.fit(x_train_S, y_train)\n",
    "y8_pred = rgr8.predict(x_test_S)\n",
    "print('нормированные данные\\nMSE', metrics.mean_squared_error(y_test, y8_pred), '\\nR2: ', metrics.r2_score(y_test, y8_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = np.arange(40)\n",
    "y = np.zeros_like(x, dtype= float)\n",
    "k = 100\n",
    "for _ in range(k):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], shuffle=True,\n",
    "                                                     stratify=df.iloc[:,-1], train_size=0.8)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train) #делаем такую функцию для нормирования по x_train\n",
    "    x_train_S = scaler.transform(x_train)\n",
    "    x_test_S = scaler.transform(x_test)\n",
    "    for i in range(1,41):\n",
    "        rgr8 = KNeighborsRegressor(n_neighbors=i)\n",
    "        rgr8.fit(x_train_S, y_train)\n",
    "        y8_pred = rgr8.predict(x_test_S)\n",
    "        y[i-1] += metrics.r2_score(y_test, y8_pred)\n",
    "y /=k\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.plot(x, y)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = np.arange(5)\n",
    "y = np.zeros_like(x, dtype= float)\n",
    "k = 10\n",
    "for _ in range(k):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], shuffle=True,\n",
    "                                                     stratify=df.iloc[:,-1], train_size=0.8)\n",
    "    for i in range(1,6):\n",
    "        rgr7= RandomForestRegressor(max_depth=23, n_estimators=i*100) #Регрессия лесом\n",
    "        rgr7.fit(x_train, y_train)\n",
    "        y7_pred = rgr7.predict(x_test)\n",
    "        y[i-1] += metrics.r2_score(y_test, y7_pred)\n",
    "y /=k\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.plot(x*100, y)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nMSE 0.3539348919728388 \n",
      "R2:  0.5353576929160251\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], shuffle=True,\n",
    "                                                     stratify=df.iloc[:,-1], train_size=0.8, random_state=1240)\n",
    "rgr10= RandomForestRegressor(max_depth=23, n_estimators=500) #Регрессия лесом\n",
    "rgr10.fit(x_train, y_train)\n",
    "y10_pred = rgr10.predict(x_test)\n",
    "print('nMSE', metrics.mean_squared_error(y_test, y10_pred), '\\nR2: ', metrics.r2_score(y_test, y10_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "x = np.arange(100)\n",
    "y = np.zeros_like(x, dtype= float)\n",
    "k = 10\n",
    "a=0.01\n",
    "pol3 = PolynomialFeatures(degree=3) #делаем третьи степени, добавляет их в выборку\n",
    "for _ in range(k):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], shuffle=True,\n",
    "                                                     stratify=df.iloc[:,-1], train_size=0.8)\n",
    "    \n",
    "    p3_x_train = pol3.fit_transform(x_train) #добавляем вторые степени и перекрестные члены\n",
    "    p3_x_test = pol3.fit_transform(x_test)\n",
    "    for i in range(1,2):\n",
    "        rgr5= Lasso(alpha=a*i, max_iter=50000) #Регрессия лассо\n",
    "        rgr5.fit(p3_x_train, y_train)\n",
    "        y5_pred = rgr5.predict(p3_x_test)\n",
    "        y[i-1] += metrics.r2_score(y_test, y5_pred)\n",
    "y /=k\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = plt.plot(x*a, y)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('MSE', metrics.mean_squared_error(y_test, y5_pred), '\\nR2: ', metrics.r2_score(y_test, y5_pred)) #Убили 4 коэффициента, которые незначимы\n",
    "print(rgr5.coef_,rgr5.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ненормированные данные\n",
      "MSE 0.643868556287703 \n",
      "R2:  0.15473557923386405\n",
      "нормированные данные\n",
      "MSE 0.4542777200339155 \n",
      "R2:  0.40362859757380265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "rgr9 = SVR()\n",
    "rgr9.fit(x_train, y_train)\n",
    "y9_pred = rgr9.predict(x_test)\n",
    "print('ненормированные данные\\nMSE', metrics.mean_squared_error(y_test, y9_pred), '\\nR2: ', metrics.r2_score(y_test, y9_pred))\n",
    "x_train_S = scaler.transform(x_train)\n",
    "x_test_S = scaler.transform(x_test)\n",
    "rgr9.fit(x_train_S, y_train)\n",
    "y9_pred = rgr9.predict(x_test_S)\n",
    "print('нормированные данные\\nMSE', metrics.mean_squared_error(y_test, y9_pred), '\\nR2: ', metrics.r2_score(y_test, y9_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамблевые алгоритмы\n",
    "\n",
    "Слабый ученик- одиночный вариант обучения (желательно с небольшой предсказательной силой, но не случайная)\n",
    "\n",
    "Один из них это случайный лес\n",
    "\n",
    "Стэкинг - собираем результаты разных моделей с одного набора данных, далее собираем результаты - они будут данными для финальной модели (делает предсказание на резльтате промежуточных результатов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsRegressor(n_neighbors=7),\n",
    "    RandomForestRegressor(max_depth=7, n_estimators=50, random_state=1240),\n",
    "    SVR()\n",
    "]\n",
    "meta_x = []\n",
    "meta_X = []\n",
    "for model in models:\n",
    "    model.fit(x_train_S, y_train)\n",
    "    meta_x.append(model.predict(x_train_S).reshape(-1,1))\n",
    "    meta_X.append(model.predict(x_test_S).reshape(-1,1))\n",
    "meta_x = np.hstack(meta_x)\n",
    "meta_X = np.hstack(meta_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.14285714 5.91511976 6.00710305]\n",
      " [5.57142857 5.22887182 5.03723699]\n",
      " [5.         5.1053893  4.92885718]\n",
      " ...\n",
      " [6.14285714 6.11212169 5.90948608]\n",
      " [6.28571429 6.23799374 6.10148985]\n",
      " [5.85714286 5.43705115 5.69182704]]\n"
     ]
    }
   ],
   "source": [
    "print(meta_x) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нормированные данные\n",
      "MSE 0.433638963760836 \n",
      "R2:  0.43072295743364775\n"
     ]
    }
   ],
   "source": [
    "rgr10 = LinearRegression()\n",
    "rgr10.fit(meta_x, y_train)\n",
    "y10_pred = rgr10.predict(meta_X)\n",
    "print('нормированные данные\\nMSE', metrics.mean_squared_error(y_test, y10_pred), '\\nR2: ', metrics.r2_score(y_test, y10_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бэггинг\n",
    "\n",
    "Берем несколько выборок и обучаем на можно одинаковых моделях, после делаем опять мета ученика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бустинг\n",
    "\n",
    "Каждый последующий ученик пытается улучшить предыдущего\n",
    "\n",
    "Адаптивный вариант (Adaboost) - для данных у хорошим результатом делаем малые веса, а для больших ошибок большие. Будет пытаться улучшать только плохие данные \n",
    "\n",
    "Градиентный вариант (GradBoost) - делаем функцию потерь от чего-либо (MSE) в зависимости от гиперпараметров системы (градиент MSE -- сумма|y-Y| ), постепенно убиваем коэффициенты или что-то такое для уменьшения функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нормированные данные\n",
      "MSE 0.3630126896535415 \n",
      "R2:  0.5234404478145533\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "rgr11 = GradientBoostingRegressor(n_estimators=300, learning_rate=0.1, criterion='squared_error', max_depth=7, random_state=1240)\n",
    "rgr11.fit(x_train, y_train)\n",
    "y11_pred = rgr11.predict(x_test)\n",
    "print('нормированные данные\\nMSE', metrics.mean_squared_error(y_test, y11_pred), '\\nR2: ', metrics.r2_score(y_test, y11_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost экстримальный бустинг - используем ещё регуляризацию как в лассо"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from xgboost improt XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мой код\n",
    "haha = pd.read_csv('haha.csv', delimiter=';')\n",
    "haha.columns = haha.iloc[0,:]\n",
    "haha = haha.drop([0])\n",
    "\n",
    "haha.head(80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(haha.iloc[:,1:], haha.iloc[:,0], shuffle=True,\n",
    "                                                      train_size=0.90)\n",
    "rgr = GradientBoostingRegressor(n_estimators=30000, learning_rate=0.1, criterion='squared_error', max_depth=7, random_state=1240)\n",
    "rgr.fit(x_train, y_train)\n",
    "y_pred = rgr.predict(x_test)\n",
    "print('нормированные данные\\nMSE', metrics.mean_squared_error(y_test, y_pred), '\\nR2: ', metrics.r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haha2 = pd.DataFrame(np.array(y_test).T)\n",
    "haha2['pred'] = y_pred\n",
    "\n",
    "haha2.head(20)\n",
    "# Конец кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8324d19f5d79336f29b0627dbb0ec3fd2d0d106838580e141c4c14a4b8340fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
